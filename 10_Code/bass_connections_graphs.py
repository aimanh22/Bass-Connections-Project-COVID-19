# -*- coding: utf-8 -*-
"""Bass_Connections_Graphs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UmtNIpKH7M0viwjEIpXinP0rmwn1zFPC
"""

!pip install basemap

"""## Importing Headers"""

import re
import numpy as np
import pandas as pd
import networkx as nx
from random import random
import matplotlib.pyplot as plt
from mpl_toolkits.basemap import Basemap as Basemap
from statsmodels.iolib.summary2 import summary_col

"""#Fetching Pre-COVID data (Census 2011)"""

data=pd.read_csv("./Inter_migrant_network_2011.csv")
data=data.dropna()

#Preprocess and format state names
def convert_string(text):
  #print(text)
  result = re.search('State - (.*) ', text).group(1)
  if result=="NCT OF DELHI":
    return "NCT of Delhi"
  else: 
    return result.title()
data['Destination_state']=data['Destination_state'].apply(convert_string)
values =['Last residence outside India','Countries in Asia beyond India', 'Other Countries', 'Unclassifiable' ]
data = data[data.Origin_state.isin(values)==False]

data

data['Total migrants employment']=data['Total migrants employment'].apply(lambda x: x.replace(',',''))
data['Total migrants employment']=data['Total migrants employment'].apply(float)

data.to_csv(r'.\migarnt_network2011.txt', header=None, index=None, sep=',', mode='a')

data.to_csv('migrant_network_cleaned_2011.csv')

"""#Fetching Post-COVID Data"""

#Fecthing and Preprocessing
post_covid_raw=pd.read_csv("/content/raw_labor_covid_migrant_data.csv")
post_covid_raw['Migrants_returned']=post_covid_raw['Migrants_returned'].apply(lambda x: x.replace(',',''))
post_covid_raw['Migrants_returned']=post_covid_raw['Migrants_returned'].apply(float)
post_covid_raw['State']=post_covid_raw['State'].replace(' ','')
post_covid_raw=post_covid_raw.set_index('State')

post_covid_raw

post_covid_train_adjusted=data.copy()
total_migrants=post_covid_train_adjusted.groupby('Origin_state')['Total migrants employment'].sum()
def func(row):
  return row['Total migrants employment']/total_migrants[row['Origin_state']]
post_covid_train_adjusted['pct_composition']=post_covid_train_adjusted.apply(func, axis=1)
post_covid_train_adjusted

def func_pred(row):
  return round(row['pct_composition']*post_covid_raw.loc[row['Origin_state'],'Migrants_returned'])
post_covid_train_adjusted['Estimated_Returned_Migrants_labor']=post_covid_train_adjusted.apply(func_pred,axis=1)

post_covid_train_adjusted

post_covid_train_adjusted.to_csv('estimated_labor_census_flows.csv')

post_covid_train_adjusted['Total migrants employment']=post_covid_train_adjusted['Total migrants employment']-post_covid_train_adjusted['Estimated_Returned_Migrants_labor']

pd.concat([post_covid_raw['Migrants_returned'],total_migrants],axis=1)

post_covid_train_adjusted.loc[post_covid_train_adjusted['Total migrants employment']<0,'Total migrants employment'].sum()

data['Total migrants employment'].sum()

3364350.0/12553449.0 #577 observations and nearly 25% of the migrants can't be traced

post_covid_data_migrant=post_covid_train_adjusted.copy()

"""Raw Data Graphs"""

m = Basemap(
         projection='merc',
         lat_0=54.5,
         lon_0=-4.36,
         llcrnrlon=68.0,
         llcrnrlat=6.,
         urcrnrlon=97.,
         urcrnrlat=37.0,
         resolution='l',
         suppress_ticks=True)
pos_data=pd.read_csv('Latlong.csv')
pos_data["State.Name"]=pos_data["State.Name"].apply(lambda x: x.title())
pos_data['latitude']=pos_data['latitude'].apply(float)
pos_data['longitude']=pos_data['longitude'].apply(float)
pos_data.at[8,'State.Name']="NCT of Delhi"
pos = {}
mx, my = m(pos_data['longitude'].values, pos_data['latitude'].values)
for count, elem in enumerate (pos_data['State.Name']):
    pos[elem] = (mx[count], my[count])

raw_total_inmigrants=data.groupby('Destination_state')['Total migrants employment'].sum()
raw_total_inmigrants=raw_total_inmigrants.to_frame()
raw_total_inmigrants['State']=raw_total_inmigrants.index
raw_total_inmigrants

G_raw_pre=nx.from_pandas_edgelist(raw_total_inmigrants, source="State",target="State")
plt.figure(figsize = (100,50))

node_size = [v*.1 for v in raw_total_inmigrants['Total migrants employment'].values]

#nx.draw_networkx_nodes(G_raw_pre , pos = pos, cmap=plt.get_cmap('YlGnBu'), node_color = values, alpha = 0.2, node_size = node_size)
nx.draw_networkx_nodes(G_raw_pre , pos = pos, cmap=plt.get_cmap('YlGnBu'), node_color =raw_total_inmigrants['Total migrants employment'].values , alpha = 0.7, node_size = node_size)
nx.draw_networkx_labels(G_raw_pre,pos=pos,font_size=24)
m.readshapefile('./Admin2', 'states', drawbounds = True, linewidth=1)
#m.drawcountries(linewidth = 3)
#m.drawstates(linewidth = 0.2)
#m.drawcoastlines(linewidth=3)
plt.tight_layout()
plt.savefig("./map_pre_covid_data.png", format = "png", dpi = 300)
plt.show()

post_covid_raw['State']=post_covid_raw.index
G_raw_post=nx.from_pandas_edgelist(post_covid_raw, source="State",target="State")
plt.figure(figsize = (100,50))

max_mig=max(post_covid_raw['Migrants_returned'].values)
node_color = [(v/max_mig, 0, 0) for v in post_covid_raw['Migrants_returned'].values]
node_size = [v*.1 for v in post_covid_raw['Migrants_returned'].values]

nx.draw_networkx_nodes(G_raw_post , pos = pos, cmap=plt.get_cmap('Reds') , node_color = post_covid_raw['Migrants_returned'].values, alpha = 0.7, node_size = node_size, label=True)
nx.draw_networkx_labels(G_raw_post,pos=pos, font_size=24)
m.readshapefile('./Admin2', 'states', drawbounds = True, linewidth=1)
#m.drawcountries(linewidth = 3)
#m.drawstates(linewidth = 0.2)
#m.drawcoastlines(linewidth=3)
plt.tight_layout()
plt.savefig("./map_post_covid_data_migrants_returned_raw.png", format = "png", dpi = 300)
plt.show()

"""### Calculating the centralities"""

G_pre= nx.from_pandas_edgelist(data, source='Origin_state',target='Destination_state',edge_attr='Total migrants employment',create_using = nx.DiGraph())
G_post= nx.from_pandas_edgelist(post_covid_data_migrant, source='Origin_state',target='Destination_state',edge_attr='Total migrants employment',create_using = nx.DiGraph())

pre_dict=nx.eigenvector_centrality(G_pre,weight='Total migrants employment')
post_dict=nx.eigenvector_centrality(G_post,weight='Total migrants employment')

"""##Calculated Graphs"""

plt.figure(figsize = (100,50))

node_color = [(random(), random(), random()) for _i in range(len(G_pre.nodes()))]
node_size = [v * 200000 for v in pre_dict.values()]
edges,weights = zip(*nx.get_edge_attributes(G_pre,'Total migrants employment').items())
val = [w/max(weights)*10 for w in weights]
values=[v for v in pre_dict.values()]

nx.draw_networkx_nodes(G_pre , pos = pos, cmap=plt.get_cmap('YlGnBu'), node_color = values, alpha = 0.7, node_size = node_size, label=True)
nx.draw_networkx_edges(G_pre , pos = pos, edge_color='red',
                        alpha=0.1, width=val, arrows = True)
nx.draw_networkx_labels(G_pre,pos=pos, font_size=24)
m.readshapefile('./Admin2', 'states', drawbounds = True, linewidth=1)
#m.drawcountries(linewidth = 3)
#m.drawstates(linewidth = 0.2)
#m.drawcoastlines(linewidth=3)
plt.tight_layout()
plt.savefig("./map_pre_covid_network.png", format = "png", dpi = 300)
plt.show()

plt.figure(figsize = (100,50))
node_size = [v * 200000 for v in post_dict.values()]
edges,weights = zip(*nx.get_edge_attributes(G_post,'Total migrants employment').items())
val = [w/max(weights)*10 for w in weights]
values=[v for v in post_dict.values()]

nx.draw_networkx_nodes(G_post , pos = pos, cmap=plt.get_cmap('YlGnBu'), node_color = values, alpha = 0.7, node_size = node_size, label=True)
nx.draw_networkx_edges(G_post , pos = pos, edge_color='red',
                        alpha=0.1, width=val, arrows = True)
nx.draw_networkx_labels(G_post,pos=pos, font_size=24)
m.readshapefile('./Admin2', 'states', drawbounds = True, linewidth=1)
#m.drawcountries(linewidth = 3)
#m.drawstates(linewidth = 0.2)
#m.drawcoastlines(linewidth=3)
plt.tight_layout()
plt.savefig("./map_post_covid_network.png", format = "png", dpi = 300)
plt.show()

